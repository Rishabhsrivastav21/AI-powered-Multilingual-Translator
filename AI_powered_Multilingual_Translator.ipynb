{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishabhsrivastav21/AI-powered-Multilingual-Translator/blob/main/AI_powered_Multilingual_Translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9sulG01AHjLy"
      },
      "outputs": [],
      "source": [
        "# == CELL 1: Install Dependencies ==\n",
        "!pip install -q torch transformers gradio langdetect sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2rqWsS5Ijs1",
        "outputId": "f912da4a-1d16-4963-f37a-2f29c5cb6829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading optimized NLLB-200 model for 100 languages...\n"
          ]
        }
      ],
      "source": [
        "# == CELL 2: Load Optimized Model ==\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import gradio as gr\n",
        "from langdetect import detect as detect_lang, LangDetectException\n",
        "\n",
        "print(\"Loading optimized NLLB-200 model for 100 languages...\")\n",
        "\n",
        "model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Configure for 100-language support\n",
        "tokenizer.model_max_length = 1024\n",
        "print(f\"✅ Model ready for 100 languages (max {tokenizer.model_max_length} tokens)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Faf33l8Ip_u"
      },
      "outputs": [],
      "source": [
        " #== CELL 3: Optimized Language Support ==\n",
        "# Top 100 languages with enhanced coverage\n",
        "lang_codes = {\n",
        "    # European Languages (20)\n",
        "    \"english\": \"eng_Latn\", \"spanish\": \"spa_Latn\", \"french\": \"fra_Latn\",\n",
        "    \"german\": \"deu_Latn\", \"italian\": \"ita_Latn\", \"portuguese\": \"por_Latn\",\n",
        "    \"russian\": \"rus_Cyrl\", \"dutch\": \"nld_Latn\", \"polish\": \"pol_Latn\",\n",
        "    \"ukrainian\": \"ukr_Cyrl\", \"romanian\": \"ron_Latn\", \"greek\": \"ell_Grek\",\n",
        "    \"hungarian\": \"hun_Latn\", \"bulgarian\": \"bul_Cyrl\", \"czech\": \"ces_Latn\",\n",
        "    \"swedish\": \"swe_Latn\", \"danish\": \"dan_Latn\", \"finnish\": \"fin_Latn\",\n",
        "    \"norwegian\": \"nob_Latn\", \"croatian\": \"hrv_Latn\",\n",
        "\n",
        "    # Asian Languages (25)\n",
        "    \"chinese\": \"zho_Hans\", \"japanese\": \"jpn_Jpan\", \"korean\": \"kor_Hang\",\n",
        "    \"hindi\": \"hin_Deva\", \"arabic\": \"ara_Arab\", \"bengali\": \"ben_Beng\",\n",
        "    \"tamil\": \"tam_Taml\", \"telugu\": \"tel_Telu\", \"marathi\": \"mar_Deva\",\n",
        "    \"urdu\": \"urd_Arab\", \"thai\": \"tha_Thai\", \"vietnamese\": \"vie_Latn\",\n",
        "    \"indonesian\": \"ind_Latn\", \"malay\": \"msa_Latn\", \"filipino\": \"fil_Latn\",\n",
        "    \"persian\": \"pes_Arab\", \"punjabi\": \"pan_Guru\", \"gujarati\": \"guj_Gujr\",\n",
        "    \"kannada\": \"kan_Knda\", \"malayalam\": \"mal_Mlym\", \"sinhala\": \"sin_Sinh\",\n",
        "    \"nepali\": \"npi_Deva\", \"khmer\": \"khm_Khmr\", \"lao\": \"lao_Laoo\",\n",
        "    \"burmese\": \"mya_Mymr\",\n",
        "\n",
        "    # African Languages (15)\n",
        "    \"swahili\": \"swh_Latn\", \"yoruba\": \"yor_Latn\", \"hausa\": \"hau_Latn\",\n",
        "    \"igbo\": \"ibo_Latn\", \"amharic\": \"amh_Ethi\", \"somali\": \"som_Latn\",\n",
        "    \"zulu\": \"zul_Latn\", \"xhosa\": \"xho_Latn\", \"shona\": \"sna_Latn\",\n",
        "    \"afrikaans\": \"afr_Latn\", \"kinyarwanda\": \"kin_Latn\", \"luganda\": \"lug_Latn\",\n",
        "    \"tigrinya\": \"tir_Ethi\", \"oromo\": \"gaz_Latn\", \"sesotho\": \"sot_Latn\",\n",
        "\n",
        "    # Other Key Languages (40)\n",
        "    \"turkish\": \"tur_Latn\", \"hebrew\": \"heb_Hebr\", \"farsi\": \"pes_Arab\",\n",
        "    \"pashto\": \"pbt_Arab\", \"kazakh\": \"kaz_Cyrl\", \"uzbek\": \"uzn_Latn\",\n",
        "    \"azerbaijani\": \"azj_Latn\", \"armenian\": \"hye_Armn\", \"georgian\": \"kat_Geor\",\n",
        "    \"mongolian\": \"khk_Cyrl\", \"tibetan\": \"bod_Tibt\", \"sanskrit\": \"san_Deva\",\n",
        "    \"albanian\": \"als_Latn\", \"belarusian\": \"bel_Cyrl\", \"bosnian\": \"bos_Latn\",\n",
        "    \"catalan\": \"cat_Latn\", \"estonian\": \"est_Latn\", \"galician\": \"glg_Latn\",\n",
        "    \"icelandic\": \"isl_Latn\", \"irish\": \"gle_Latn\", \"latvian\": \"lvs_Latn\",\n",
        "    \"lithuanian\": \"lit_Latn\", \"macedonian\": \"mkd_Cyrl\", \"maltese\": \"mlt_Latn\",\n",
        "    \"serbian\": \"srp_Cyrl\", \"slovak\": \"slk_Latn\", \"slovenian\": \"slv_Latn\",\n",
        "    \"welsh\": \"cym_Latn\", \"basque\": \"eus_Latn\", \"breton\": \"bre_Latn\",\n",
        "    \"frisian\": \"fry_Latn\", \"hawaiian\": \"haw_Latn\", \"luxembourgish\": \"ltz_Latn\",\n",
        "    \"scottish gaelic\": \"gla_Latn\", \"yiddish\": \"ydd_Hebr\", \"sindhi\": \"snd_Arab\",\n",
        "    \"kurdish\": \"kmr_Latn\", \"tajik\": \"tgk_Cyrl\", \"turkmen\": \"tuk_Latn\"\n",
        "\n",
        "}\n",
        "\n",
        "# Enhanced ISO mapping for better auto-detection\n",
        "iso_to_nllb = {\n",
        "    \"af\": \"afr_Latn\", \"am\": \"amh_Ethi\", \"ar\": \"ara_Arab\", \"az\": \"azb_Arab\",\n",
        "    \"be\": \"bel_Latn\", \"bg\": \"bul_Cyrl\", \"bn\": \"ben_Beng\", \"bs\": \"bos_Latn\",\n",
        "    \"ca\": \"cat_Latn\", \"ceb\": \"ceb_Latn\", \"cs\": \"ces_Latn\", \"cy\": \"cym_Latn\",\n",
        "    \"da\": \"dan_Latn\", \"de\": \"deu_Latn\", \"el\": \"ell_Grek\", \"en\": \"eng_Latn\",\n",
        "    \"eo\": \"epo_Latn\", \"es\": \"spa_Latn\", \"et\": \"est_Latn\", \"eu\": \"eus_Latn\",\n",
        "    \"fa\": \"pes_Arab\", \"fi\": \"fin_Latn\", \"fil\": \"fil_Latn\", \"fr\": \"fra_Latn\",\n",
        "    \"fy\": \"fry_Latn\", \"ga\": \"gle_Latn\", \"gd\": \"gla_Latn\", \"gl\": \"glg_Latn\",\n",
        "    \"gu\": \"guj_Gujr\", \"he\": \"heb_Hebr\", \"hi\": \"hin_Deva\", \"hmn\": \"hmn_Latn\",\n",
        "    \"hr\": \"hrv_Latn\", \"ht\": \"hat_Latn\", \"hu\": \"hun_Latn\", \"hy\": \"hye_Armn\",\n",
        "    \"id\": \"ind_Latn\", \"ig\": \"ibo_Latn\", \"is\": \"isl_Latn\", \"it\": \"ita_Latn\",\n",
        "    \"ja\": \"jpn_Jpan\", \"jv\": \"jav_Latn\", \"ka\": \"kat_Geor\", \"kk\": \"kaz_Cyrl\",\n",
        "    \"km\": \"khm_Khmr\", \"kn\": \"kan_Knda\", \"ko\": \"kor_Hang\", \"ku\": \"kmr_Latn\",\n",
        "    \"ky\": \"kir_Cyrl\", \"la\": \"lat_Latn\", \"lb\": \"ltz_Latn\", \"lo\": \"lao_Laoo\",\n",
        "    \"lt\": \"lit_Latn\", \"lv\": \"lvs_Latn\", \"mg\": \"mlg_Latn\", \"mi\": \"mri_Latn\",\n",
        "    \"mk\": \"mkd_Cyrl\", \"ml\": \"mal_Mlym\", \"mn\": \"mon_Cyrl\", \"mr\": \"mar_Deva\",\n",
        "    \"ms\": \"msa_Latn\", \"mt\": \"mlt_Latn\", \"my\": \"mya_Mymr\", \"ne\": \"npi_Deva\",\n",
        "    \"nl\": \"nld_Latn\", \"no\": \"nor_Latn\", \"ny\": \"nya_Latn\", \"pa\": \"pan_Guru\",\n",
        "    \"pl\": \"pol_Latn\", \"ps\": \"pus_Arab\", \"pt\": \"por_Latn\", \"ro\": \"ron_Latn\",\n",
        "    \"ru\": \"rus_Cyrl\", \"sd\": \"snd_Arab\", \"si\": \"sin_Sinh\", \"sk\": \"slk_Latn\",\n",
        "    \"sl\": \"slv_Latn\", \"sm\": \"smo_Latn\", \"sn\": \"sna_Latn\", \"so\": \"som_Latn\",\n",
        "    \"sq\": \"als_Latn\", \"sr\": \"srp_Cyrl\", \"st\": \"sot_Latn\", \"su\": \"sun_Latn\",\n",
        "    \"sv\": \"swe_Latn\", \"sw\": \"swh_Latn\", \"ta\": \"tam_Taml\", \"te\": \"tel_Telu\",\n",
        "    \"tg\": \"tgk_Cyrl\", \"th\": \"tha_Thai\", \"tk\": \"tuk_Latn\", \"tl\": \"fil_Latn\",\n",
        "    \"tr\": \"tur_Latn\", \"tt\": \"tat_Cyrl\", \"ug\": \"uig_Arab\", \"uk\": \"ukr_Cyrl\",\n",
        "    \"ur\": \"urd_Arab\", \"uz\": \"uzn_Latn\", \"vi\": \"vie_Latn\", \"xh\": \"xho_Latn\",\n",
        "    \"yi\": \"ydd_Hebr\", \"yo\": \"yor_Latn\", \"zh\": \"zho_Hans\", \"zu\": \"zul_Latn\"\n",
        "}\n",
        "\n",
        "\n",
        "available_languages = [\"auto\"] + sorted(list(lang_codes.keys()))\n",
        "target_languages = [lang for lang in available_languages if lang != \"auto\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfrj4mV5LmiN"
      },
      "outputs": [],
      "source": [
        "# == CELL 4: Robust Translation Function ==\n",
        "def translate_text_100(text, source_lang, target_lang, max_length=5000):\n",
        "    # Input validation\n",
        "    if not text.strip():\n",
        "        return \"⚠️ Please enter text to translate\"\n",
        "\n",
        "    if len(text) > max_length:\n",
        "        return f\"⚠️ Text exceeds {max_length} character limit\"\n",
        "\n",
        "    # Language resolution\n",
        "    try:\n",
        "        if source_lang.lower() == \"auto\":\n",
        "            if len(text.strip()) < 10:\n",
        "                return \"⚠️ Enter at least 10 characters for auto-detection\"\n",
        "            try:\n",
        "                detected = detect_lang(text)\n",
        "                src_code = iso_to_nllb.get(detected.split('-')[0].lower())\n",
        "                if not src_code:\n",
        "                    return f\"⚠️ Detected language '{detected}' not supported\"\n",
        "            except LangDetectException:\n",
        "                return \"⚠️ Language detection failed. Please specify source\"\n",
        "        else:\n",
        "            src_code = lang_codes.get(source_lang.lower())\n",
        "            if not src_code:\n",
        "                return f\"❌ Source language '{source_lang}' not supported\"\n",
        "\n",
        "        tgt_code = lang_codes.get(target_lang.lower())\n",
        "        if not tgt_code:\n",
        "            return f\"❌ Target language '{target_lang}' not supported\"\n",
        "\n",
        "        # Tokenization and translation\n",
        "        tokenizer.src_lang = src_code\n",
        "        inputs = tokenizer(\n",
        "            text,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=1024\n",
        "        ).to(model.device)\n",
        "\n",
        "        # Language token handling\n",
        "        if hasattr(tokenizer, 'lang_code_to_id'):\n",
        "            bos_token_id = tokenizer.lang_code_to_id[tgt_code]\n",
        "        else:\n",
        "            bos_token_id = tokenizer.convert_tokens_to_ids(tgt_code)\n",
        "            if bos_token_id is None:\n",
        "                return f\"❌ Language code '{tgt_code}' not in vocabulary\"\n",
        "\n",
        "        # Generation with optimized parameters\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                forced_bos_token_id=bos_token_id,\n",
        "                max_new_tokens=1024,\n",
        "                num_beams=5,\n",
        "                early_stopping=True,\n",
        "                no_repeat_ngram_size=3,\n",
        "                length_penalty=1.2\n",
        "            )\n",
        "\n",
        "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        if \"CUDA out of memory\" in str(e):\n",
        "            return \"⚠️ GPU memory full. Try shorter text or restart Colab\"\n",
        "        return f\"❌ Runtime error: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error: {str(e)}\"\n",
        "    finally:\n",
        "        torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EVMf8OqrLtDw"
      },
      "outputs": [],
      "source": [
        "# == CELL 5: Enhanced Interface ==\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"## 🌐 AI Translator (100 Languages)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            text_input = gr.Textbox(\n",
        "                label=\"📝 Input Text\",\n",
        "                placeholder=\"Enter text (max 5000 chars)...\",\n",
        "                lines=8,\n",
        "                max_length=5000\n",
        "            )\n",
        "            with gr.Row():\n",
        "                src_lang = gr.Dropdown(\n",
        "                    choices=available_languages,\n",
        "                    value=\"auto\",\n",
        "                    label=\"Source Language\"\n",
        "                )\n",
        "                tgt_lang = gr.Dropdown(\n",
        "                    choices=target_languages,\n",
        "                    value=\"arabic\",\n",
        "                    label=\"Target Language\"\n",
        "                )\n",
        "            btn = gr.Button(\"🔁 Translate\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output = gr.Textbox(\n",
        "                label=\"✅ Translation\",\n",
        "                lines=8,\n",
        "                interactive=False,\n",
        "                show_copy_button=True\n",
        "            )\n",
        "\n",
        "    # Add examples\n",
        "    examples = gr.Examples(\n",
        "        examples=[\n",
        "            [\"Hello, how are you?\", \"english\", \"spanish\"],\n",
        "            [\"This is a test of the translation system\", \"auto\", \"french\"],\n",
        "            [\"اللغة العربية جميلة\", \"auto\", \"english\"]\n",
        "        ],\n",
        "        inputs=[text_input, src_lang, tgt_lang]\n",
        "    )\n",
        "\n",
        "    btn.click(\n",
        "        fn=translate_text_100,\n",
        "        inputs=[text_input, src_lang, tgt_lang],\n",
        "        outputs=output,\n",
        "        show_progress=\"full\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WoUmv5-1LyQX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "77f3249d-5045-4534-e5a0-c896b057915e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1d5954c1574e068971.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1d5954c1574e068971.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# == CELL 6: Launch ==\n",
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyON4JjRdpGiM6d8pIWQNg+R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}